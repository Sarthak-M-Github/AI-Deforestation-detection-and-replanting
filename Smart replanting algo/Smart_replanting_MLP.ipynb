{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import joblib\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# -------------------- STEP 1: Load & Preprocess Data --------------------\n",
        "df = pd.read_csv(\"smart_replanting_dataset.csv\")\n",
        "\n",
        "X = df.drop([\"Label\", \"Grouped_Label\"], axis=1)\n",
        "y = df[\"Grouped_Label\"]\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X_encoded = pd.get_dummies(X, columns=[\"Region\", \"Soil_Type\"])\n",
        "\n",
        "# Label encode target\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "df_encoded = X_encoded.copy()\n",
        "df_encoded[\"Target\"] = y_encoded\n",
        "\n",
        "# ‚öñÔ∏è Moderate upsampling (not too extreme)\n",
        "mean_size = int(df_encoded[\"Target\"].value_counts().mean() * 1.5)\n",
        "df_balanced = pd.concat([\n",
        "    group.sample(mean_size, replace=True, random_state=42)\n",
        "    for _, group in df_encoded.groupby(\"Target\")\n",
        "])\n",
        "\n",
        "X_bal = df_balanced.drop(\"Target\", axis=1)\n",
        "y_bal = df_balanced[\"Target\"]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_bal)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_bal, test_size=0.2, stratify=y_bal, random_state=42\n",
        ")\n",
        "\n",
        "# Convert targets to categorical for Keras\n",
        "num_classes = len(le.classes_)\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# -------------------- STEP 2: Build & Train Model --------------------\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "loss_fn = CategoricalCrossentropy(label_smoothing=0.05)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=RMSprop(learning_rate=0.0002),\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=252,\n",
        "    batch_size=2,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# -------------------- STEP 3: Evaluate --------------------\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n‚úÖ Accuracy: {acc:.2f}\")\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# -------------------- STEP 4: Save for Streamlit --------------------\n",
        "\n",
        "model.save(\"ann_model.keras\")  # Recommended Keras format\n",
        "joblib.dump(scaler, \"ann_scaler.pkl\")\n",
        "joblib.dump(le, \"ann_label_encoder.pkl\")\n",
        "joblib.dump(X_bal.columns.tolist(), \"ann_feature_columns.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ilxaAe2b4g6",
        "outputId": "6a1b177c-7a13-4ae8-99c0-9a1d527074f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\n",
            "‚úÖ Accuracy: 0.60\n",
            "\n",
            "üìä Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "DroughtResistant       0.60      1.00      0.75        12\n",
            "      FastGrower       0.71      0.38      0.50        13\n",
            "        Hardwood       0.42      0.38      0.40        13\n",
            "        Mangrove       0.81      1.00      0.90        13\n",
            "       Medicinal       0.50      0.46      0.48        13\n",
            "       ShadeTree       0.50      0.38      0.43        13\n",
            "\n",
            "        accuracy                           0.60        77\n",
            "       macro avg       0.59      0.60      0.58        77\n",
            "    weighted avg       0.59      0.60      0.57        77\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ann_feature_columns.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}